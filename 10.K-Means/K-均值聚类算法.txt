K-均值聚类算法：发现给定数据集的k个簇，簇个数k由用户给定，每个簇通过其质心来描述

1.工作流程：
	。首先，随机确定k个初始点作为质心，
	。然后，将数据集中的每个点分配到一个簇中
		具体来讲，为每个点找距其最近的质心，并将其分配给该质心对应的簇，
	     该步完成后，每个簇的质心更新为该簇所有点的平均值

   上述过程的伪代码如下：
	创建k个点作为起始质心（经常是随机选择）
	当任意一个点的簇分配结果发生改变时：
		对数据集中的每个数据点：
			计算该数据点到所有质心的距离，并找出最小的距离
			将数据点分配到距其最近的簇中
		对每个簇，重新计算簇的质心位置（计算簇中所有点的均值作为质心）

注意：数据集上K-均值算法的性能会受到所选距离计算方法的影响

2.使用后处理来提高聚类性能：

	K-均值算法收敛但聚类效果较差的原因是，K-均值算法收敛到了局部最小值，而非

全局最小值（局部最小值指结果还可以但并非最好结果，全局最小值是可能的最好结果）

一个用于度量聚类效果的指标是SSE（误差平方和）：

	SSE越小，则表示数据点越接近它们的质心，聚类效果越好

一种肯定可以降低SSE的方法是增加簇的个数，但这违背了聚类的目标

聚类的目标是：保持簇数目不变的情况下提高簇的质量

簇划分：
	在SSE较大的簇上，再接着使用K-均值聚类

簇合并：
	两种量化方法：
		。合并最近的质心
		。合并两个使得SSE增幅最小的质心


3.二分K-均值算法：克服K-均值算法收敛于局部最小值的问题
	主要思想：首先将所有点作为一个簇，然后将该簇一分为二，之后选择其中一个簇
   继续进行划分，选择哪一个簇进行划分取决于对其划分是否可以最大程度降低SSE的值
   基于SSE的划分过程不断重复，直到得到用户指定的簇数目为止
	
  上述过程的伪代码：
	将所有点看成一个簇
	当簇数目小于k时：
		对于每个簇：
			计算总误差
			在给定的簇上面进行K-均值聚类（k=2）
			计算将该簇一分为二之后的总误差
			选择一个较小的误差
		选择使得误差最小的那个簇进行划分操作
	
  另外一种做法是：选择SSE最大的簇进行划分，直到簇数目达到用户指定的数目为止

整个过程难度并不是很大，注意在对簇进行实际划分时的数据修改问题
























